{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the second part of the web scraping project. This part we will take the reviews and create a pipeline that will determine the sentiment of future reviews and see if it is Good, Neutral, Or Bad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the Packages we Need \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets load our training dataset we have created, This is from the first part of the project.  \n",
    "\n",
    "training_df = pd.read_csv('training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Validation data for later use\n",
    "\n",
    "valid_df = pd.read_csv('valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>RatingValue</th>\n",
       "      <th>DatePublished</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mariachi’s Restaurant</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-06-29</td>\n",
       "      <td>If you want to go for excellent customer servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98 Aroma</td>\n",
       "      <td>negative</td>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>If I was able to give 0 stars, I would. This i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dynasty Chinese Cuisine</td>\n",
       "      <td>negative</td>\n",
       "      <td>2019-02-21</td>\n",
       "      <td>Came here to celebrate my Friends Birthday, Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carisma</td>\n",
       "      <td>negative</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>Disappointed.\\n\\nI came here for dinner and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carisma</td>\n",
       "      <td>negative</td>\n",
       "      <td>2019-10-20</td>\n",
       "      <td>- Not worth for its price. Both service and qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>KINKA IZAKAYA ORIGINAL</td>\n",
       "      <td>positive</td>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>My friend got the lunch set which includes a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>KINKA IZAKAYA ORIGINAL</td>\n",
       "      <td>positive</td>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>Absolutely loved this spot when I went with fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Giulietta</td>\n",
       "      <td>positive</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>Good date place. The atmosphere was phenomenal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>KINKA IZAKAYA ORIGINAL</td>\n",
       "      <td>positive</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>I would share this, but I'm too shellfish \\n.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Giulietta</td>\n",
       "      <td>positive</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>Part of a longer review...\\n\\n\"With Giulietta,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name RatingValue DatePublished  \\\n",
       "0      Mariachi’s Restaurant    negative    2018-06-29   \n",
       "1                   98 Aroma    negative    2019-04-07   \n",
       "2    Dynasty Chinese Cuisine    negative    2019-02-21   \n",
       "3                    Carisma    negative    2019-01-10   \n",
       "4                    Carisma    negative    2019-10-20   \n",
       "..                       ...         ...           ...   \n",
       "310   KINKA IZAKAYA ORIGINAL    positive    2020-05-04   \n",
       "311   KINKA IZAKAYA ORIGINAL    positive    2020-05-04   \n",
       "312                Giulietta    positive    2019-06-12   \n",
       "313   KINKA IZAKAYA ORIGINAL    positive    2020-05-14   \n",
       "314                Giulietta    positive    2019-01-06   \n",
       "\n",
       "                                                Review  \n",
       "0    If you want to go for excellent customer servi...  \n",
       "1    If I was able to give 0 stars, I would. This i...  \n",
       "2    Came here to celebrate my Friends Birthday, Fo...  \n",
       "3    Disappointed.\\n\\nI came here for dinner and th...  \n",
       "4    - Not worth for its price. Both service and qu...  \n",
       "..                                                 ...  \n",
       "310  My friend got the lunch set which includes a d...  \n",
       "311  Absolutely loved this spot when I went with fr...  \n",
       "312  Good date place. The atmosphere was phenomenal...  \n",
       "313  I would share this, but I'm too shellfish \\n.\\...  \n",
       "314  Part of a longer review...\\n\\n\"With Giulietta,...  \n",
       "\n",
       "[315 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check that we imported it \n",
    "\n",
    "training_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex training set to clean it up.\n",
    "\n",
    "training_df.set_index('Name',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex validation set to clean it up.\n",
    "\n",
    "valid_df.set_index('Name',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into categorical \n",
    "\n",
    "training_df.RatingValue = training_df.RatingValue.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into categorical \n",
    "\n",
    "valid_df.RatingValue = valid_df.RatingValue.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RatingValue      category\n",
       "DatePublished      object\n",
       "Review             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the Data types are okay \n",
    "\n",
    "training_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets Create our cateogories \n",
    "\n",
    "categories = ['negative', 'neutral', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['negative', 'neutral', 'positive'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure that there are only three. \n",
    "\n",
    "training_df.RatingValue.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315\n",
      "315\n"
     ]
    }
   ],
   "source": [
    "#There should be 315 entries, lets verify. \n",
    "\n",
    "print(len(training_df.Review))\n",
    "print(len(training_df.RatingValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you want to go for excellent customer service, go for it. Great people, great location. \n",
      "\n",
      "However, if you are going for the food. Skip this place and try something else. Food was mediocre, tasteless and expensive. I'm sorry but I wish I could go back in time and save myself $66.\n"
     ]
    }
   ],
   "source": [
    "#I am just gonna check that the first review is good when i load it. \n",
    "\n",
    "print(\"\\n\".join(training_df.Review[0].split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(315, 4359)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use count vectorizer for counts for the reviews \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(training_df.Review)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3824"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check a random word. See that we get around 3824 instances. \n",
    "\n",
    "count_vect.vocabulary_['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(315, 4359)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we use the trasnformer for tf-idf instead. \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(315, 4359)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just for cosmetic purposes \n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now use MNB model here for our lanaguage model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, training_df.RatingValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test run of data. Lets just create some random reviews and see if the model is able to correctly label review. \n",
    "\n",
    "docs_new = ['Food was so good i loved it so much', 'food was okay.']\n",
    "\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Food was so good i loved it so much' => positive\n",
      "'food was okay.' => neutral\n"
     ]
    }
   ],
   "source": [
    "#Looks good so far. Pretty cool, it's able to determine the sentiment of a random review we created. \n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we already created the seperate parts for the sentiment classifer, lets load a data pipeline so that we can streamline\n",
    "#the process. \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the pipeline to the traning data set that we created eariler. \n",
    "\n",
    "text_clf.fit(training_df.Review, training_df.RatingValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of the model is then:\n",
      "0.562962962962963\n"
     ]
    }
   ],
   "source": [
    "#Lets now use our model to test of the validation set\n",
    "# Load test data here. \n",
    "\n",
    "docs_test = valid_df.Review\n",
    "predicted = text_clf.predict(docs_test)\n",
    "Acc = np.mean(predicted == valid_df.RatingValue)\n",
    "\n",
    "#looking at some metrics. \n",
    "\n",
    "print(\"The Accuracy of the model is then:\")\n",
    "print( Acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.56      0.62        45\n",
      "     neutral       0.44      0.71      0.54        45\n",
      "    positive       0.73      0.42      0.54        45\n",
      "\n",
      "    accuracy                           0.56       135\n",
      "   macro avg       0.62      0.56      0.56       135\n",
      "weighted avg       0.62      0.56      0.56       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Here is the confusion matrix/ F1 score. \n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(valid_df.RatingValue, predicted,\n",
    "    target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And we are done not bad for a simple model we created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
